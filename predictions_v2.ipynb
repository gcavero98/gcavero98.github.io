{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:15:37.338467Z",
     "start_time": "2023-06-28T17:15:37.182157Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.2.2'"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "M, m, p = sklearn.__version__.split('.')\n",
    "display(sklearn.__version__)\n",
    "assert int(M) == 1\n",
    "assert int(m) >= 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:15:37.611621Z",
     "start_time": "2023-06-28T17:15:37.192989Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "data_folders = [\n",
    "    pathlib.Path(f'./data/bicing/truncated/{y}') for y in [2022]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:15:37.693709Z",
     "start_time": "2023-06-28T17:15:37.208699Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "pandas_kwargs = {\n",
    "    'index_col': 0,\n",
    "}\n",
    "df = pd.concat([pd.read_csv(file, **pandas_kwargs) for data_folder in data_folders for file in\n",
    "                data_folder.glob('*/*.csv')]).drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:15:54.062348Z",
     "start_time": "2023-06-28T17:15:37.219405Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    datetime=lambda x: pd.to_datetime(x.datetime),\n",
    "    percentage_docks_available=df.num_docks_available / (df.num_docks_available + df.num_bikes_available),\n",
    ").drop(columns=['num_docks_available', 'num_bikes_available']).sort_values(['station_id', 'datetime'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:00.683867Z",
     "start_time": "2023-06-28T17:15:54.070948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "assert (df.percentage_docks_available > 1).sum() == 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:00.725043Z",
     "start_time": "2023-06-28T17:16:00.688660Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add station info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "   station_id            datetime  year  month  day  hour  \\\n0           1 2022-01-01 00:00:00  2022      1    1     0   \n1           1 2022-01-01 00:00:00  2022      1    1     0   \n2           1 2022-01-01 01:00:00  2022      1    1     1   \n3           1 2022-01-01 02:00:00  2022      1    1     2   \n4           1 2022-01-01 03:00:00  2022      1    1     3   \n\n   percentage_docks_available        lat       lon  altitude  post_code  \n0                    0.608696  41.397978  2.180107        16       8013  \n1                    0.625000  41.397978  2.180107        16       8013  \n2                    0.681818  41.397978  2.180107        16       8013  \n3                    0.722826  41.397978  2.180107        16       8013  \n4                    0.737458  41.397978  2.180107        16       8013  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_id</th>\n      <th>datetime</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>percentage_docks_available</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>altitude</th>\n      <th>post_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2022-01-01 00:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.608696</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>8013</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2022-01-01 00:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.625000</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>8013</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2022-01-01 01:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.681818</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>8013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2022-01-01 02:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.722826</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>8013</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2022-01-01 03:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.737458</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>8013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_info = pd.read_csv('./data/bicing_info.csv')\n",
    "df = pd.merge(left=df, right=station_info[['station_id', 'lat', 'lon', 'altitude', 'post_code']],\n",
    "              on=['station_id'])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:02.602655Z",
     "start_time": "2023-06-28T17:16:00.721283Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### climate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "df_climate_ = pd.read_csv('./data/clima.csv', parse_dates=['time'])\n",
    "\n",
    "df_climate = df_climate_.assign(\n",
    "    year=df_climate_.time.dt.year,\n",
    "    month=df_climate_.time.dt.month,\n",
    "    day=df_climate_.time.dt.day,\n",
    "    hour=df_climate_.time.dt.hour\n",
    ")\n",
    "df = pd.merge(left=df, right=df_climate.drop(columns=['time']), on=['hour', 'day', 'month', 'year'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:06.689678Z",
     "start_time": "2023-06-28T17:16:02.607420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "         station_id            datetime  year  month  day  hour  \\\n0                 1 2022-01-01 00:00:00  2022      1    1     0   \n1                 1 2022-01-01 00:00:00  2022      1    1     0   \n2                 2 2022-01-01 00:00:00  2022      1    1     0   \n3                 2 2022-01-01 00:00:00  2022      1    1     0   \n4                 3 2022-01-01 00:00:00  2022      1    1     0   \n...             ...                 ...   ...    ...  ...   ...   \n4419981         515 2022-01-13 11:00:00  2022      1   13    11   \n4419982         516 2022-01-13 11:00:00  2022      1   13    11   \n4419983         517 2022-01-13 11:00:00  2022      1   13    11   \n4419984         518 2022-01-13 11:00:00  2022      1   13    11   \n4419985         519 2022-01-13 11:00:00  2022      1   13    11   \n\n         percentage_docks_available        lat       lon  altitude  post_code  \\\n0                          0.608696  41.397978  2.180107        16       8013   \n1                          0.625000  41.397978  2.180107        16       8013   \n2                          0.356322  41.395488  2.177198        17       8013   \n3                          0.364943  41.395488  2.177198        17       8013   \n4                          0.555556  41.394156  2.181331        11       8013   \n...                             ...        ...       ...       ...        ...   \n4419981                    0.971429  41.435207  2.194800        19       8030   \n4419982                    0.250000  41.435460  2.200157        15       8030   \n4419983                    0.300000  41.462095  2.178959        44       8033   \n4419984                    1.000000  41.424689  2.157049       112       8032   \n4419985                    0.946970  41.424655  2.166289       110       8032   \n\n         temperature_2m  total_cloud_cover  total_precipitation  windspeed_10m  \n0            282.597015           0.339310         4.111789e-07       2.181416  \n1            282.597015           0.339310         4.111789e-07       2.181416  \n2            282.597015           0.339310         4.111789e-07       2.181416  \n3            282.597015           0.339310         4.111789e-07       2.181416  \n4            282.597015           0.339310         4.111789e-07       2.181416  \n...                 ...                ...                  ...            ...  \n4419981      282.674469           0.007935         0.000000e+00       2.058891  \n4419982      282.674469           0.007935         0.000000e+00       2.058891  \n4419983      282.674469           0.007935         0.000000e+00       2.058891  \n4419984      282.674469           0.007935         0.000000e+00       2.058891  \n4419985      282.674469           0.007935         0.000000e+00       2.058891  \n\n[4419986 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_id</th>\n      <th>datetime</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>percentage_docks_available</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>altitude</th>\n      <th>post_code</th>\n      <th>temperature_2m</th>\n      <th>total_cloud_cover</th>\n      <th>total_precipitation</th>\n      <th>windspeed_10m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2022-01-01 00:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.608696</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>8013</td>\n      <td>282.597015</td>\n      <td>0.339310</td>\n      <td>4.111789e-07</td>\n      <td>2.181416</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2022-01-01 00:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.625000</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>8013</td>\n      <td>282.597015</td>\n      <td>0.339310</td>\n      <td>4.111789e-07</td>\n      <td>2.181416</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2022-01-01 00:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.356322</td>\n      <td>41.395488</td>\n      <td>2.177198</td>\n      <td>17</td>\n      <td>8013</td>\n      <td>282.597015</td>\n      <td>0.339310</td>\n      <td>4.111789e-07</td>\n      <td>2.181416</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>2022-01-01 00:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.364943</td>\n      <td>41.395488</td>\n      <td>2.177198</td>\n      <td>17</td>\n      <td>8013</td>\n      <td>282.597015</td>\n      <td>0.339310</td>\n      <td>4.111789e-07</td>\n      <td>2.181416</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>2022-01-01 00:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.555556</td>\n      <td>41.394156</td>\n      <td>2.181331</td>\n      <td>11</td>\n      <td>8013</td>\n      <td>282.597015</td>\n      <td>0.339310</td>\n      <td>4.111789e-07</td>\n      <td>2.181416</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4419981</th>\n      <td>515</td>\n      <td>2022-01-13 11:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>13</td>\n      <td>11</td>\n      <td>0.971429</td>\n      <td>41.435207</td>\n      <td>2.194800</td>\n      <td>19</td>\n      <td>8030</td>\n      <td>282.674469</td>\n      <td>0.007935</td>\n      <td>0.000000e+00</td>\n      <td>2.058891</td>\n    </tr>\n    <tr>\n      <th>4419982</th>\n      <td>516</td>\n      <td>2022-01-13 11:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>13</td>\n      <td>11</td>\n      <td>0.250000</td>\n      <td>41.435460</td>\n      <td>2.200157</td>\n      <td>15</td>\n      <td>8030</td>\n      <td>282.674469</td>\n      <td>0.007935</td>\n      <td>0.000000e+00</td>\n      <td>2.058891</td>\n    </tr>\n    <tr>\n      <th>4419983</th>\n      <td>517</td>\n      <td>2022-01-13 11:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>13</td>\n      <td>11</td>\n      <td>0.300000</td>\n      <td>41.462095</td>\n      <td>2.178959</td>\n      <td>44</td>\n      <td>8033</td>\n      <td>282.674469</td>\n      <td>0.007935</td>\n      <td>0.000000e+00</td>\n      <td>2.058891</td>\n    </tr>\n    <tr>\n      <th>4419984</th>\n      <td>518</td>\n      <td>2022-01-13 11:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>13</td>\n      <td>11</td>\n      <td>1.000000</td>\n      <td>41.424689</td>\n      <td>2.157049</td>\n      <td>112</td>\n      <td>8032</td>\n      <td>282.674469</td>\n      <td>0.007935</td>\n      <td>0.000000e+00</td>\n      <td>2.058891</td>\n    </tr>\n    <tr>\n      <th>4419985</th>\n      <td>519</td>\n      <td>2022-01-13 11:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>13</td>\n      <td>11</td>\n      <td>0.946970</td>\n      <td>41.424655</td>\n      <td>2.166289</td>\n      <td>110</td>\n      <td>8032</td>\n      <td>282.674469</td>\n      <td>0.007935</td>\n      <td>0.000000e+00</td>\n      <td>2.058891</td>\n    </tr>\n  </tbody>\n</table>\n<p>4419986 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:06.777334Z",
     "start_time": "2023-06-28T17:16:06.699901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# merge with previous hours\n",
    "df = df.sort_values(['station_id', 'datetime']).assign(\n",
    "    day_of_week=lambda x: x.datetime.dt.day_of_week,\n",
    "    is_weekend=lambda x: x.day_of_week >= 5,\n",
    "    is_night=lambda x: np.bitwise_or(x.hour >= 20, x.hour <= 7),\n",
    "    is_work_morning=lambda x: np.bitwise_and(x.hour >= 6, x.hour <= 10) & np.bitwise_not(x.is_weekend),\n",
    "    is_summer=lambda x: x.month.between(6, 8),\n",
    "    ctx_1=lambda x: x.percentage_docks_available.shift(1),\n",
    "    ctx_2=lambda x: x.percentage_docks_available.shift(2),\n",
    "    ctx_3=lambda x: x.percentage_docks_available.shift(3),\n",
    "    ctx_4=lambda x: x.percentage_docks_available.shift(4),\n",
    "    station_id_aux=lambda x: x.station_id.shift(4),\n",
    "    altitude=lambda x: x.altitude.astype(int)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:20.252725Z",
     "start_time": "2023-06-28T17:16:06.756896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "df = df \\\n",
    "    .query('not ctx_1.isnull()') \\\n",
    "    .query('not ctx_2.isnull()') \\\n",
    "    .query('not ctx_3.isnull()') \\\n",
    "    .query('not ctx_4.isnull()') \\\n",
    "    .query('station_id == station_id_aux') \\\n",
    "    .drop(columns=['station_id_aux']) \\\n",
    "    .query('not percentage_docks_available.isnull()')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:41.761890Z",
     "start_time": "2023-06-28T17:16:20.260277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "dfnans = df.isna().sum()\n",
    "assert dfnans[dfnans > 0].empty"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:42.236950Z",
     "start_time": "2023-06-28T17:16:41.766213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "      station_id            datetime  year  month  day  hour  \\\n2020           1 2022-01-01 03:00:00  2022      1    1     3   \n2525           1 2022-01-01 04:00:00  2022      1    1     4   \n3030           1 2022-01-01 05:00:00  2022      1    1     5   \n3535           1 2022-01-01 06:00:00  2022      1    1     6   \n4040           1 2022-01-01 07:00:00  2022      1    1     7   \n\n      percentage_docks_available        lat       lon  altitude  ...  \\\n2020                    0.737458  41.397978  2.180107        16  ...   \n2525                    0.717391  41.397978  2.180107        16  ...   \n3030                    0.717391  41.397978  2.180107        16  ...   \n3535                    0.672101  41.397978  2.180107        16  ...   \n4040                    0.639706  41.397978  2.180107        16  ...   \n\n      windspeed_10m  day_of_week  is_weekend  is_night  is_work_morning  \\\n2020       2.155734            5        True      True            False   \n2525       2.059913            5        True      True            False   \n3030       1.985322            5        True      True            False   \n3535       1.993759            5        True      True            False   \n4040       2.046561            5        True      True            False   \n\n      is_summer     ctx_1     ctx_2     ctx_3     ctx_4  \n2020      False  0.722826  0.681818  0.625000  0.608696  \n2525      False  0.737458  0.722826  0.681818  0.625000  \n3030      False  0.717391  0.737458  0.722826  0.681818  \n3535      False  0.717391  0.717391  0.737458  0.722826  \n4040      False  0.672101  0.717391  0.717391  0.737458  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_id</th>\n      <th>datetime</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>percentage_docks_available</th>\n      <th>lat</th>\n      <th>lon</th>\n      <th>altitude</th>\n      <th>...</th>\n      <th>windspeed_10m</th>\n      <th>day_of_week</th>\n      <th>is_weekend</th>\n      <th>is_night</th>\n      <th>is_work_morning</th>\n      <th>is_summer</th>\n      <th>ctx_1</th>\n      <th>ctx_2</th>\n      <th>ctx_3</th>\n      <th>ctx_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020</th>\n      <td>1</td>\n      <td>2022-01-01 03:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.737458</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>...</td>\n      <td>2.155734</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.722826</td>\n      <td>0.681818</td>\n      <td>0.625000</td>\n      <td>0.608696</td>\n    </tr>\n    <tr>\n      <th>2525</th>\n      <td>1</td>\n      <td>2022-01-01 04:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.717391</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>...</td>\n      <td>2.059913</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.737458</td>\n      <td>0.722826</td>\n      <td>0.681818</td>\n      <td>0.625000</td>\n    </tr>\n    <tr>\n      <th>3030</th>\n      <td>1</td>\n      <td>2022-01-01 05:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.717391</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>...</td>\n      <td>1.985322</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.717391</td>\n      <td>0.737458</td>\n      <td>0.722826</td>\n      <td>0.681818</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>1</td>\n      <td>2022-01-01 06:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0.672101</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>...</td>\n      <td>1.993759</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.717391</td>\n      <td>0.717391</td>\n      <td>0.737458</td>\n      <td>0.722826</td>\n    </tr>\n    <tr>\n      <th>4040</th>\n      <td>1</td>\n      <td>2022-01-01 07:00:00</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0.639706</td>\n      <td>41.397978</td>\n      <td>2.180107</td>\n      <td>16</td>\n      <td>...</td>\n      <td>2.046561</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0.672101</td>\n      <td>0.717391</td>\n      <td>0.717391</td>\n      <td>0.737458</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:42.327480Z",
     "start_time": "2023-06-28T17:16:42.242770Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from sklearn import model_selection, linear_model, ensemble, neighbors, preprocessing, metrics, pipeline, compose"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:42.388310Z",
     "start_time": "2023-06-28T17:16:42.331834Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# CrossValidation\n",
    "\n",
    "scoring = 'neg_root_mean_squared_error'\n",
    "\n",
    "\n",
    "def get_cv_scores(model, X: pd.DataFrame, y: pd.Series, cv=4, verbose=0):\n",
    "    if verbose > 0: display(f'{X.shape=}')\n",
    "    if verbose > 0: display(f'{y.shape=}')\n",
    "\n",
    "    return model_selection.cross_val_score(\n",
    "        model, X, y,\n",
    "        scoring=scoring,\n",
    "        cv=model_selection.TimeSeriesSplit(cv),\n",
    "        verbose=verbose,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:42.521423Z",
     "start_time": "2023-06-28T17:16:42.398178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# Custom Regressor\n",
    "from dataclasses import dataclass\n",
    "from sklearn import linear_model\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# create model per\n",
    "@dataclass\n",
    "class BicingRegression:\n",
    "    grouping_column_name: str\n",
    "\n",
    "    regressor_class: type = None\n",
    "    clip: bool = True\n",
    "    verbose: int = 0\n",
    "\n",
    "    groups_: List[int] = None\n",
    "    regressors_: Dict[int, object] = None\n",
    "    generic_regressor_: object = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.regressors_ = self.regressors_ or {}\n",
    "        self.regressor_class = self.regressor_class or linear_model.LinearRegression\n",
    "\n",
    "    def fit(self, X, y, weights=None):\n",
    "        assert y.isna().sum() == 0\n",
    "        if self.verbose >= 10:\n",
    "            print(f'{type(X)=}')\n",
    "            print(f'{type(y)=}')\n",
    "        self.groups_ = X.loc[:, self.grouping_column_name].unique()\n",
    "\n",
    "        for ii, group in enumerate(self.groups_):\n",
    "            if self.verbose > 0:\n",
    "                print(f'Training regressor {ii + 1}/{len(self.groups_)}')\n",
    "            self.regressors_[group] = self.regressor_class()\n",
    "\n",
    "            X_ = X.query(f'{self.grouping_column_name} == {group}').drop(columns=[self.grouping_column_name])\n",
    "            y_ = y.loc[X_.index]\n",
    "            self.regressors_[group].fit(X_, y_)\n",
    "\n",
    "        if self.verbose > 0:\n",
    "            print(f'Training generic regressor')\n",
    "        self.generic_regressor_ = self.regressor_class()\n",
    "        self.generic_regressor_.fit(X.drop(columns=[self.grouping_column_name]), y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = pd.DataFrame(\n",
    "            index=X.index,\n",
    "            columns=['prediction']\n",
    "        )\n",
    "\n",
    "        for group in self.groups_:\n",
    "            X_ = X.query(f'{self.grouping_column_name} == {group}').drop(columns=[self.grouping_column_name])\n",
    "            if len(X_) == 0:\n",
    "                continue\n",
    "            y_pred = self.regressors_[group].predict(X_)\n",
    "            results.loc[X_.index, 'prediction'] = y_pred\n",
    "\n",
    "        for unseen_group in X[self.grouping_column_name].unique():\n",
    "            if unseen_group not in self.groups_:\n",
    "                X_ = X.query(f'{self.grouping_column_name} == {unseen_group}').drop(columns=[self.grouping_column_name])\n",
    "                if len(X_) == 0:\n",
    "                    continue\n",
    "                y_pred = self.generic_regressor_.predict(X_)\n",
    "                results.loc[X_.index, 'prediction'] = y_pred\n",
    "\n",
    "        if self.clip:\n",
    "            return results.assign(prediction=lambda x: np.clip(x.prediction, 0, 1))['prediction']\n",
    "        else:\n",
    "            return results['prediction']\n",
    "\n",
    "    @property\n",
    "    def coef_(self):\n",
    "        coefs = []\n",
    "        for regressor in self.regressors_.values():\n",
    "            coefs.append(regressor.coef_)\n",
    "        coefs = np.array(coefs)\n",
    "        print(coefs.shape)\n",
    "\n",
    "        return np.mean(coefs, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:16:42.667825Z",
     "start_time": "2023-06-28T17:16:42.409348Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "# pipes = [\n",
    "#     {\n",
    "#         'model': pipeline.Pipeline(\n",
    "#             [\n",
    "#                 (\"transformer\", compose.ColumnTransformer(\n",
    "#                     [\n",
    "#                         ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(2)]),\n",
    "#                         ('std', preprocessing.MinMaxScaler((0, 1)), [\"hour\"]),\n",
    "#                     ],\n",
    "#                     remainder=\"drop\", )\n",
    "#                  ),\n",
    "#                 (\"regressor\", ensemble.RandomForestRegressor(verbose=3, n_jobs=-1))\n",
    "#             ]\n",
    "#         ),\n",
    "#         'weights': None,\n",
    "#     },\n",
    "#     {\n",
    "#         'model': pipeline.Pipeline(\n",
    "#             [\n",
    "#                 (\"transformer\", compose.ColumnTransformer(\n",
    "#                     [\n",
    "#                         ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "#                         ('12bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=12, subsample=None),\n",
    "#                          [\"hour\"]),\n",
    "#                         ('4bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=4, subsample=None),\n",
    "#                          [\"altitude\", \"temperature_2m\"]),\n",
    "#                     ],\n",
    "#                     remainder=\"drop\", )\n",
    "#                  ),\n",
    "#                 (\"regressor\", ensemble.RandomForestRegressor(verbose=1, n_jobs=-1))\n",
    "#             ]\n",
    "#         ),\n",
    "#         'weights': None,\n",
    "#     },\n",
    "#     {\n",
    "#         'model': pipeline.Pipeline(\n",
    "#             [\n",
    "#                 (\"transformer\", compose.ColumnTransformer(\n",
    "#                     [\n",
    "#                         ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "#                         ('std', preprocessing.StandardScaler(), [\"temperature_2m\"]),\n",
    "#                     ],\n",
    "#                     remainder=\"drop\", )\n",
    "#                  ),\n",
    "#                 (\"regressor\", linear_model.LinearRegression())\n",
    "#             ]\n",
    "#         ),\n",
    "#         'weights': None,\n",
    "#     },\n",
    "#     {\n",
    "#         'model': pipeline.Pipeline(\n",
    "#             [\n",
    "#                 (\"transformer\", compose.ColumnTransformer(\n",
    "#                     [\n",
    "#                         ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "#                         ('std', preprocessing.StandardScaler(), [\"temperature_2m\", \"altitude\"]),\n",
    "#                     ],\n",
    "#                     remainder=\"drop\", )\n",
    "#                  ),\n",
    "#                 (\"regressor\", linear_model.LinearRegression())\n",
    "#             ]\n",
    "#         ),\n",
    "#         'weights': None,\n",
    "#     },\n",
    "#     {\n",
    "#         'model': pipeline.Pipeline(\n",
    "#             [\n",
    "#                 (\"transformer\", compose.ColumnTransformer(\n",
    "#                     [\n",
    "#                         ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "#                         ('std', preprocessing.StandardScaler(), [\"temperature_2m\", \"altitude\"]),\n",
    "#                         ('coord', preprocessing.StandardScaler(), [\"lat\", \"lon\"]),\n",
    "#                         # ('cat', preprocessing.OneHotEncoder(handle_unknown=\"ignore\"), [\"post_code\"]),\n",
    "#                         ('clean', preprocessing.FunctionTransformer(feature_names_out='one-to-one'), ['station_id']),\n",
    "#                     ],\n",
    "#                     remainder=\"drop\",\n",
    "#                     sparse_threshold=0,\n",
    "#                 ).set_output(transform='pandas')\n",
    "#                  ),\n",
    "#                 (\"regressor\", BicingRegression(\n",
    "#                     grouping_column_name='clean__station_id',\n",
    "#                     verbose=10\n",
    "#                 ))\n",
    "#             ]\n",
    "#         ),\n",
    "#         'weights': None,\n",
    "#     },\n",
    "#     {\n",
    "#         'model': pipeline.Pipeline(\n",
    "#             [\n",
    "#                 (\"transformer\", compose.ColumnTransformer(\n",
    "#                     [\n",
    "#                         ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "#                         ('12bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=12, subsample=None),\n",
    "#                          [\"hour\"]),\n",
    "#                         ('4bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=4, subsample=None),\n",
    "#                          [\"altitude\", \"temperature_2m\"]),\n",
    "#                     ],\n",
    "#                     remainder=\"drop\", )\n",
    "#                  ),\n",
    "#                 (\"regressor\", ensemble.RandomForestRegressor(verbose=1, n_jobs=-1))\n",
    "#             ]\n",
    "#         ),\n",
    "#         'weights': None,\n",
    "#     },\n",
    "\n",
    "# ]\n",
    "\n",
    "Y_COLUMN = 'percentage_docks_available'\n",
    "pipes = [\n",
    "    {\n",
    "        'name': 'baseline',\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        ('previous_hours', preprocessing.FunctionTransformer(feature_names_out=\"one-to-one\"),\n",
    "                         [f\"ctx_{ii + 1}\" for ii in range(2)]),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", linear_model.LinearRegression())\n",
    "            ]\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'improved linear regression (std features)',\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        (\n",
    "                            'previous_hours', preprocessing.FunctionTransformer(feature_names_out=\"one-to-one\"),\n",
    "                            [f\"ctx_{ii + 1}\" for ii in range(2)]\n",
    "                        ),\n",
    "                        (\n",
    "                            'std', preprocessing.StandardScaler(), [\"hour\", \"altitude\", \"temperature_2m\"]\n",
    "                        ),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", linear_model.LinearRegression())\n",
    "            ]\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'linear regression (features are KBins)',\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        ('previous_hours', preprocessing.FunctionTransformer(feature_names_out=\"one-to-one\"),\n",
    "                         [f\"ctx_{ii + 1}\" for ii in range(2)]),\n",
    "                        ('12bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=12, subsample=None),\n",
    "                         [\"hour\"]),\n",
    "                        ('4bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=4, subsample=None),\n",
    "                         [\"altitude\", \"temperature_2m\"]),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", linear_model.LinearRegression())\n",
    "            ]\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'random forest (std features)',\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        (\n",
    "                            'previous_hours', preprocessing.FunctionTransformer(feature_names_out=\"one-to-one\"),\n",
    "                            [f\"ctx_{ii + 1}\" for ii in range(2)]\n",
    "                        ),\n",
    "                        (\n",
    "                            'std', preprocessing.StandardScaler(), [\"hour\", \"altitude\", \"temperature_2m\"]\n",
    "                        ),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", ensemble.RandomForestRegressor(n_estimators=200, min_samples_leaf=0.05, verbose=3, n_jobs=-1))\n",
    "            ]\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': 'random forest (more features)',\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        (\n",
    "                            'previous_hours', preprocessing.FunctionTransformer(feature_names_out=\"one-to-one\"),\n",
    "                            [f\"ctx_{ii + 1}\" for ii in range(2)]\n",
    "                        ),\n",
    "                        (\n",
    "                            '4bins', preprocessing.KBinsDiscretizer(encode=\"onehot\", n_bins=4, subsample=None),\n",
    "                            [\"altitude\", \"temperature_2m\"]\n",
    "                        ),\n",
    "                        (\n",
    "                            '12bins', preprocessing.KBinsDiscretizer(encode=\"onehot\", n_bins=12, subsample=None),\n",
    "                            [\"hour\"]\n",
    "                        ),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", ensemble.RandomForestRegressor(n_estimators=50,min_samples_leaf=0.05, verbose=3, n_jobs=-1))\n",
    "            ]\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        'name': '1 regression per station (more features)',\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        (\n",
    "                            'previous_hours', preprocessing.FunctionTransformer(feature_names_out=\"one-to-one\"),\n",
    "                            [f\"ctx_{ii + 1}\" for ii in range(2)]\n",
    "                        ),\n",
    "                        (\n",
    "                            '4bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=4, subsample=None),\n",
    "                            [\"altitude\", \"temperature_2m\"]\n",
    "                        ),\n",
    "                        (\n",
    "                            '12bins', preprocessing.KBinsDiscretizer(encode=\"ordinal\", n_bins=12, subsample=None),\n",
    "                            [\"hour\"]\n",
    "                        ),\n",
    "                        (\n",
    "                            'clean', preprocessing.FunctionTransformer(feature_names_out=\"one-to-one\"),\n",
    "                            [\"station_id\"]\n",
    "                        ),\n",
    "                    ],\n",
    "                    remainder=\"drop\",\n",
    "                    sparse_threshold=0\n",
    "                ).set_output(transform='pandas')),\n",
    "                (\"regressor\", BicingRegression(grouping_column_name='clean__station_id', verbose=3))\n",
    "            ]\n",
    "        )\n",
    "    },\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:19.017594Z",
     "start_time": "2023-06-28T17:36:18.843846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:24.241672Z",
     "start_time": "2023-06-28T17:36:24.236130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "df_ = df.query(f'month < 5').sort_values('datetime')\n",
    "SHOW_CV_STEPS = False\n",
    "#\n",
    "# for ii, dd in enumerate(pipes):\n",
    "#     pipe = dd['model']\n",
    "#     display(f'Running model with IDX: {ii} - {dd[\"name\"]}')\n",
    "#     display(pipe)\n",
    "#\n",
    "#     if SHOW_CV_STEPS:\n",
    "#         cv = model_selection.TimeSeriesSplit(2)\n",
    "#         for jj, (train_idx, test_idx) in enumerate(cv.split(df_.drop(columns=[Y_COLUMN]))):\n",
    "#             df_train_ = df_.iloc[train_idx].reset_index()\n",
    "#             df_test_ = df_.iloc[test_idx].reset_index()\n",
    "#\n",
    "#             pipe.fit(df_train_.drop(columns=[Y_COLUMN]), df_train_[Y_COLUMN])\n",
    "#             display(\n",
    "#                 pd.Series(\n",
    "#                     data=pipe[\"regressor\"].feature_importances_,\n",
    "#                     index=list(filter(lambda x: not x.startswith('clean'), pipe[\"transformer\"].get_feature_names_out()))\n",
    "#                 )\n",
    "#             )\n",
    "#\n",
    "#             y_test_pred = pipe.predict(df_test_.drop(columns=[Y_COLUMN]))\n",
    "#\n",
    "#             df_test_ = df_test_.assign(\n",
    "#                 y_test_pred=y_test_pred\n",
    "#             )\n",
    "#             sns.scatterplot(\n",
    "#                 data=df_test_,\n",
    "#                 x=Y_COLUMN,\n",
    "#                 y='y_test_pred',\n",
    "#                 alpha=0.2\n",
    "#             )\n",
    "#             plt.show()\n",
    "#\n",
    "#             display(np.sqrt(metrics.mean_squared_error(y_true=df_test_[Y_COLUMN], y_pred=df_test_['y_test_pred'])))\n",
    "#\n",
    "#     cv_scores = get_cv_scores(pipe, df_.drop(columns=[Y_COLUMN]), df_[Y_COLUMN], cv=3, verbose=1)\n",
    "#     display(f'{np.mean(cv_scores):0.4f}')\n",
    "#\n",
    "#     display('-' * 80)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:36:25.413388Z",
     "start_time": "2023-06-28T17:36:24.247204Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# final fit"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "       station_id  month  day  hour     ctx_4     ctx_3     ctx_2     ctx_1  \\\nindex                                                                         \n0             394      3    7     8  0.753086  0.780864  0.799383  0.824074   \n1             337      3   23    12  0.463768  0.536232  0.532609  0.601449   \n2             368      3   31     1  0.787037  0.709877  0.611111  0.601852   \n3             327      3   23    15  0.753472  0.809028  0.819444  0.736111   \n4             328      3    4    20  0.861111  0.802469  0.814815  0.827160   \n\n       year        lat  ...  total_cloud_cover  total_precipitation  \\\nindex                   ...                                           \n0      2023  41.387306  ...           0.134741                  0.0   \n1      2023  41.398624  ...           0.288515                  0.0   \n2      2023  41.396839  ...           1.000004                  0.0   \n3      2023  41.405007  ...           0.138855                  0.0   \n4      2023  41.402988  ...           0.019991                  0.0   \n\n       windspeed_10m       date  day_of_week  is_weekend  is_night  \\\nindex                                                                \n0           1.892034 2023-03-07            1       False     False   \n1           5.151473 2023-03-23            3       False     False   \n2           3.311623 2023-03-31            4       False      True   \n3           5.492265 2023-03-23            3       False     False   \n4           3.738923 2023-03-04            5        True      True   \n\n      is_work_morning  is_summer  index  \nindex                                    \n0                True      False      0  \n1               False      False      1  \n2               False      False      2  \n3               False      False      3  \n4               False      False      4  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_id</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>ctx_4</th>\n      <th>ctx_3</th>\n      <th>ctx_2</th>\n      <th>ctx_1</th>\n      <th>year</th>\n      <th>lat</th>\n      <th>...</th>\n      <th>total_cloud_cover</th>\n      <th>total_precipitation</th>\n      <th>windspeed_10m</th>\n      <th>date</th>\n      <th>day_of_week</th>\n      <th>is_weekend</th>\n      <th>is_night</th>\n      <th>is_work_morning</th>\n      <th>is_summer</th>\n      <th>index</th>\n    </tr>\n    <tr>\n      <th>index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>394</td>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0.753086</td>\n      <td>0.780864</td>\n      <td>0.799383</td>\n      <td>0.824074</td>\n      <td>2023</td>\n      <td>41.387306</td>\n      <td>...</td>\n      <td>0.134741</td>\n      <td>0.0</td>\n      <td>1.892034</td>\n      <td>2023-03-07</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>3</td>\n      <td>23</td>\n      <td>12</td>\n      <td>0.463768</td>\n      <td>0.536232</td>\n      <td>0.532609</td>\n      <td>0.601449</td>\n      <td>2023</td>\n      <td>41.398624</td>\n      <td>...</td>\n      <td>0.288515</td>\n      <td>0.0</td>\n      <td>5.151473</td>\n      <td>2023-03-23</td>\n      <td>3</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>368</td>\n      <td>3</td>\n      <td>31</td>\n      <td>1</td>\n      <td>0.787037</td>\n      <td>0.709877</td>\n      <td>0.611111</td>\n      <td>0.601852</td>\n      <td>2023</td>\n      <td>41.396839</td>\n      <td>...</td>\n      <td>1.000004</td>\n      <td>0.0</td>\n      <td>3.311623</td>\n      <td>2023-03-31</td>\n      <td>4</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>327</td>\n      <td>3</td>\n      <td>23</td>\n      <td>15</td>\n      <td>0.753472</td>\n      <td>0.809028</td>\n      <td>0.819444</td>\n      <td>0.736111</td>\n      <td>2023</td>\n      <td>41.405007</td>\n      <td>...</td>\n      <td>0.138855</td>\n      <td>0.0</td>\n      <td>5.492265</td>\n      <td>2023-03-23</td>\n      <td>3</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>328</td>\n      <td>3</td>\n      <td>4</td>\n      <td>20</td>\n      <td>0.861111</td>\n      <td>0.802469</td>\n      <td>0.814815</td>\n      <td>0.827160</td>\n      <td>2023</td>\n      <td>41.402988</td>\n      <td>...</td>\n      <td>0.019991</td>\n      <td>0.0</td>\n      <td>3.738923</td>\n      <td>2023-03-04</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load X_val\n",
    "X_val = pd.read_csv('./data/validation/X_validation.csv', index_col=\"index\")\n",
    "X_val = X_val.assign(index=X_val.index)\n",
    "\n",
    "X_val = X_val.assign(year=2023)\n",
    "\n",
    "X_val = pd.merge(\n",
    "    left=X_val,\n",
    "    right=station_info[['station_id', 'lat', 'lon', 'altitude', 'post_code']],\n",
    "    on=['station_id'],\n",
    "\n",
    ")\n",
    "X_val = pd.merge(left=X_val, right=df_climate.drop(columns=['time']), on=['hour', 'day', 'month', 'year'])\n",
    "X_val = X_val.assign(\n",
    "    date=lambda x: pd.to_datetime(dict(year=x.year, month=x.month, day=x.day)),\n",
    "    day_of_week=lambda x: x.date.dt.day_of_week,\n",
    "    is_weekend=lambda x: x.day_of_week >= 5,\n",
    "    is_night=lambda x: np.bitwise_or(x.hour >= 20, x.hour <= 7),\n",
    "    is_work_morning=lambda x: np.bitwise_and(x.hour >= 6, x.hour <= 10) & np.bitwise_not(x.is_weekend),\n",
    "    is_summer=lambda x: x.month.between(6, 8),\n",
    "    altitude=lambda x: x.altitude.astype(int),\n",
    ").rename(\n",
    "    columns={\n",
    "        'ctx-1': 'ctx_1',\n",
    "        'ctx-2': 'ctx_2',\n",
    "        'ctx-3': 'ctx_3',\n",
    "        'ctx-4': 'ctx_4',\n",
    "    }\n",
    ")\n",
    "X_val = X_val.set_index(\"index\").sort_index()\n",
    "X_val = X_val.assign(index=X_val.index)\n",
    "X_val.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:33:51.417379Z",
     "start_time": "2023-06-28T17:33:51.031525Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "'1 regression per station (more features)'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('transformer',\n                 ColumnTransformer(sparse_threshold=0,\n                                   transformers=[('previous_hours',\n                                                  FunctionTransformer(feature_names_out='one-to-one'),\n                                                  ['ctx_1', 'ctx_2']),\n                                                 ('4bins',\n                                                  KBinsDiscretizer(encode='ordinal',\n                                                                   n_bins=4,\n                                                                   subsample=None),\n                                                  ['altitude',\n                                                   'temperature_2m']),\n                                                 ('12bins',\n                                                  KBinsDiscretizer(encode='ordinal',\n                                                                   n_bins=12,\n                                                                   subsample=None),\n                                                  ['hour']),\n                                                 ('clean',\n                                                  FunctionTransformer(feature_names_out='one-to-one'),\n                                                  ['station_id'])])),\n                ('regressor',\n                 BicingRegression(grouping_column_name='clean__station_id',\n                                  regressor_class=<class 'sklearn.linear_model._base.LinearRegression'>,\n                                  clip=True,\n                                  verbose=3,\n                                  groups_=None,\n                                  regressors_={},\n                                  generic_regressor_=None))])",
      "text/html": "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n                 ColumnTransformer(sparse_threshold=0,\n                                   transformers=[(&#x27;previous_hours&#x27;,\n                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;),\n                                                  [&#x27;ctx_1&#x27;, &#x27;ctx_2&#x27;]),\n                                                 (&#x27;4bins&#x27;,\n                                                  KBinsDiscretizer(encode=&#x27;ordinal&#x27;,\n                                                                   n_bins=4,\n                                                                   subsample=None),\n                                                  [&#x27;altitude&#x27;,\n                                                   &#x27;temperature_2m&#x27;]),\n                                                 (&#x27;12bins&#x27;,\n                                                  KBinsDiscretizer(encode=&#x27;ordinal&#x27;,\n                                                                   n_bins=12,\n                                                                   subsample=None),\n                                                  [&#x27;hour&#x27;]),\n                                                 (&#x27;clean&#x27;,\n                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;),\n                                                  [&#x27;station_id&#x27;])])),\n                (&#x27;regressor&#x27;,\n                 BicingRegression(grouping_column_name=&#x27;clean__station_id&#x27;,\n                                  regressor_class=&lt;class &#x27;sklearn.linear_model._base.LinearRegression&#x27;&gt;,\n                                  clip=True,\n                                  verbose=3,\n                                  groups_=None,\n                                  regressors_={},\n                                  generic_regressor_=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;transformer&#x27;,\n                 ColumnTransformer(sparse_threshold=0,\n                                   transformers=[(&#x27;previous_hours&#x27;,\n                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;),\n                                                  [&#x27;ctx_1&#x27;, &#x27;ctx_2&#x27;]),\n                                                 (&#x27;4bins&#x27;,\n                                                  KBinsDiscretizer(encode=&#x27;ordinal&#x27;,\n                                                                   n_bins=4,\n                                                                   subsample=None),\n                                                  [&#x27;altitude&#x27;,\n                                                   &#x27;temperature_2m&#x27;]),\n                                                 (&#x27;12bins&#x27;,\n                                                  KBinsDiscretizer(encode=&#x27;ordinal&#x27;,\n                                                                   n_bins=12,\n                                                                   subsample=None),\n                                                  [&#x27;hour&#x27;]),\n                                                 (&#x27;clean&#x27;,\n                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;),\n                                                  [&#x27;station_id&#x27;])])),\n                (&#x27;regressor&#x27;,\n                 BicingRegression(grouping_column_name=&#x27;clean__station_id&#x27;,\n                                  regressor_class=&lt;class &#x27;sklearn.linear_model._base.LinearRegression&#x27;&gt;,\n                                  clip=True,\n                                  verbose=3,\n                                  groups_=None,\n                                  regressors_={},\n                                  generic_regressor_=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=0,\n                  transformers=[(&#x27;previous_hours&#x27;,\n                                 FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;),\n                                 [&#x27;ctx_1&#x27;, &#x27;ctx_2&#x27;]),\n                                (&#x27;4bins&#x27;,\n                                 KBinsDiscretizer(encode=&#x27;ordinal&#x27;, n_bins=4,\n                                                  subsample=None),\n                                 [&#x27;altitude&#x27;, &#x27;temperature_2m&#x27;]),\n                                (&#x27;12bins&#x27;,\n                                 KBinsDiscretizer(encode=&#x27;ordinal&#x27;, n_bins=12,\n                                                  subsample=None),\n                                 [&#x27;hour&#x27;]),\n                                (&#x27;clean&#x27;,\n                                 FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;),\n                                 [&#x27;station_id&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">previous_hours</label><div class=\"sk-toggleable__content\"><pre>[&#x27;ctx_1&#x27;, &#x27;ctx_2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">4bins</label><div class=\"sk-toggleable__content\"><pre>[&#x27;altitude&#x27;, &#x27;temperature_2m&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KBinsDiscretizer</label><div class=\"sk-toggleable__content\"><pre>KBinsDiscretizer(encode=&#x27;ordinal&#x27;, n_bins=4, subsample=None)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">12bins</label><div class=\"sk-toggleable__content\"><pre>[&#x27;hour&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KBinsDiscretizer</label><div class=\"sk-toggleable__content\"><pre>KBinsDiscretizer(encode=&#x27;ordinal&#x27;, n_bins=12, subsample=None)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clean</label><div class=\"sk-toggleable__content\"><pre>[&#x27;station_id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BicingRegression</label><div class=\"sk-toggleable__content\"><pre>BicingRegression(grouping_column_name=&#x27;clean__station_id&#x27;, regressor_class=&lt;class &#x27;sklearn.linear_model._base.LinearRegression&#x27;&gt;, clip=True, verbose=3, groups_=None, regressors_={}, generic_regressor_=None)</pre></div></div></div></div></div></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training regressor 1/507\n",
      "Training regressor 2/507\n",
      "Training regressor 3/507\n",
      "Training regressor 4/507\n",
      "Training regressor 5/507\n",
      "Training regressor 6/507\n",
      "Training regressor 7/507\n",
      "Training regressor 8/507\n",
      "Training regressor 9/507\n",
      "Training regressor 10/507\n",
      "Training regressor 11/507\n",
      "Training regressor 12/507\n",
      "Training regressor 13/507\n",
      "Training regressor 14/507\n",
      "Training regressor 15/507\n",
      "Training regressor 16/507\n",
      "Training regressor 17/507\n",
      "Training regressor 18/507\n",
      "Training regressor 19/507\n",
      "Training regressor 20/507\n",
      "Training regressor 21/507\n",
      "Training regressor 22/507\n",
      "Training regressor 23/507\n",
      "Training regressor 24/507\n",
      "Training regressor 25/507\n",
      "Training regressor 26/507\n",
      "Training regressor 27/507\n",
      "Training regressor 28/507\n",
      "Training regressor 29/507\n",
      "Training regressor 30/507\n",
      "Training regressor 31/507\n",
      "Training regressor 32/507\n",
      "Training regressor 33/507\n",
      "Training regressor 34/507\n",
      "Training regressor 35/507\n",
      "Training regressor 36/507\n",
      "Training regressor 37/507\n",
      "Training regressor 38/507\n",
      "Training regressor 39/507\n",
      "Training regressor 40/507\n",
      "Training regressor 41/507\n",
      "Training regressor 42/507\n",
      "Training regressor 43/507\n",
      "Training regressor 44/507\n",
      "Training regressor 45/507\n",
      "Training regressor 46/507\n",
      "Training regressor 47/507\n",
      "Training regressor 48/507\n",
      "Training regressor 49/507\n",
      "Training regressor 50/507\n",
      "Training regressor 51/507\n",
      "Training regressor 52/507\n",
      "Training regressor 53/507\n",
      "Training regressor 54/507\n",
      "Training regressor 55/507\n",
      "Training regressor 56/507\n",
      "Training regressor 57/507\n",
      "Training regressor 58/507\n",
      "Training regressor 59/507\n",
      "Training regressor 60/507\n",
      "Training regressor 61/507\n",
      "Training regressor 62/507\n",
      "Training regressor 63/507\n",
      "Training regressor 64/507\n",
      "Training regressor 65/507\n",
      "Training regressor 66/507\n",
      "Training regressor 67/507\n",
      "Training regressor 68/507\n",
      "Training regressor 69/507\n",
      "Training regressor 70/507\n",
      "Training regressor 71/507\n",
      "Training regressor 72/507\n",
      "Training regressor 73/507\n",
      "Training regressor 74/507\n",
      "Training regressor 75/507\n",
      "Training regressor 76/507\n",
      "Training regressor 77/507\n",
      "Training regressor 78/507\n",
      "Training regressor 79/507\n",
      "Training regressor 80/507\n",
      "Training regressor 81/507\n",
      "Training regressor 82/507\n",
      "Training regressor 83/507\n",
      "Training regressor 84/507\n",
      "Training regressor 85/507\n",
      "Training regressor 86/507\n",
      "Training regressor 87/507\n",
      "Training regressor 88/507\n",
      "Training regressor 89/507\n",
      "Training regressor 90/507\n",
      "Training regressor 91/507\n",
      "Training regressor 92/507\n",
      "Training regressor 93/507\n",
      "Training regressor 94/507\n",
      "Training regressor 95/507\n",
      "Training regressor 96/507\n",
      "Training regressor 97/507\n",
      "Training regressor 98/507\n",
      "Training regressor 99/507\n",
      "Training regressor 100/507\n",
      "Training regressor 101/507\n",
      "Training regressor 102/507\n",
      "Training regressor 103/507\n",
      "Training regressor 104/507\n",
      "Training regressor 105/507\n",
      "Training regressor 106/507\n",
      "Training regressor 107/507\n",
      "Training regressor 108/507\n",
      "Training regressor 109/507\n",
      "Training regressor 110/507\n",
      "Training regressor 111/507\n",
      "Training regressor 112/507\n",
      "Training regressor 113/507\n",
      "Training regressor 114/507\n",
      "Training regressor 115/507\n",
      "Training regressor 116/507\n",
      "Training regressor 117/507\n",
      "Training regressor 118/507\n",
      "Training regressor 119/507\n",
      "Training regressor 120/507\n",
      "Training regressor 121/507\n",
      "Training regressor 122/507\n",
      "Training regressor 123/507\n",
      "Training regressor 124/507\n",
      "Training regressor 125/507\n",
      "Training regressor 126/507\n",
      "Training regressor 127/507\n",
      "Training regressor 128/507\n",
      "Training regressor 129/507\n",
      "Training regressor 130/507\n",
      "Training regressor 131/507\n",
      "Training regressor 132/507\n",
      "Training regressor 133/507\n",
      "Training regressor 134/507\n",
      "Training regressor 135/507\n",
      "Training regressor 136/507\n",
      "Training regressor 137/507\n",
      "Training regressor 138/507\n",
      "Training regressor 139/507\n",
      "Training regressor 140/507\n",
      "Training regressor 141/507\n",
      "Training regressor 142/507\n",
      "Training regressor 143/507\n",
      "Training regressor 144/507\n",
      "Training regressor 145/507\n",
      "Training regressor 146/507\n",
      "Training regressor 147/507\n",
      "Training regressor 148/507\n",
      "Training regressor 149/507\n",
      "Training regressor 150/507\n",
      "Training regressor 151/507\n",
      "Training regressor 152/507\n",
      "Training regressor 153/507\n",
      "Training regressor 154/507\n",
      "Training regressor 155/507\n",
      "Training regressor 156/507\n",
      "Training regressor 157/507\n",
      "Training regressor 158/507\n",
      "Training regressor 159/507\n",
      "Training regressor 160/507\n",
      "Training regressor 161/507\n",
      "Training regressor 162/507\n",
      "Training regressor 163/507\n",
      "Training regressor 164/507\n",
      "Training regressor 165/507\n",
      "Training regressor 166/507\n",
      "Training regressor 167/507\n",
      "Training regressor 168/507\n",
      "Training regressor 169/507\n",
      "Training regressor 170/507\n",
      "Training regressor 171/507\n",
      "Training regressor 172/507\n",
      "Training regressor 173/507\n",
      "Training regressor 174/507\n",
      "Training regressor 175/507\n",
      "Training regressor 176/507\n",
      "Training regressor 177/507\n",
      "Training regressor 178/507\n",
      "Training regressor 179/507\n",
      "Training regressor 180/507\n",
      "Training regressor 181/507\n",
      "Training regressor 182/507\n",
      "Training regressor 183/507\n",
      "Training regressor 184/507\n",
      "Training regressor 185/507\n",
      "Training regressor 186/507\n",
      "Training regressor 187/507\n",
      "Training regressor 188/507\n",
      "Training regressor 189/507\n",
      "Training regressor 190/507\n",
      "Training regressor 191/507\n",
      "Training regressor 192/507\n",
      "Training regressor 193/507\n",
      "Training regressor 194/507\n",
      "Training regressor 195/507\n",
      "Training regressor 196/507\n",
      "Training regressor 197/507\n",
      "Training regressor 198/507\n",
      "Training regressor 199/507\n",
      "Training regressor 200/507\n",
      "Training regressor 201/507\n",
      "Training regressor 202/507\n",
      "Training regressor 203/507\n",
      "Training regressor 204/507\n",
      "Training regressor 205/507\n",
      "Training regressor 206/507\n",
      "Training regressor 207/507\n",
      "Training regressor 208/507\n",
      "Training regressor 209/507\n",
      "Training regressor 210/507\n",
      "Training regressor 211/507\n",
      "Training regressor 212/507\n",
      "Training regressor 213/507\n",
      "Training regressor 214/507\n",
      "Training regressor 215/507\n",
      "Training regressor 216/507\n",
      "Training regressor 217/507\n",
      "Training regressor 218/507\n",
      "Training regressor 219/507\n",
      "Training regressor 220/507\n",
      "Training regressor 221/507\n",
      "Training regressor 222/507\n",
      "Training regressor 223/507\n",
      "Training regressor 224/507\n",
      "Training regressor 225/507\n",
      "Training regressor 226/507\n",
      "Training regressor 227/507\n",
      "Training regressor 228/507\n",
      "Training regressor 229/507\n",
      "Training regressor 230/507\n",
      "Training regressor 231/507\n",
      "Training regressor 232/507\n",
      "Training regressor 233/507\n",
      "Training regressor 234/507\n",
      "Training regressor 235/507\n",
      "Training regressor 236/507\n",
      "Training regressor 237/507\n",
      "Training regressor 238/507\n",
      "Training regressor 239/507\n",
      "Training regressor 240/507\n",
      "Training regressor 241/507\n",
      "Training regressor 242/507\n",
      "Training regressor 243/507\n",
      "Training regressor 244/507\n",
      "Training regressor 245/507\n",
      "Training regressor 246/507\n",
      "Training regressor 247/507\n",
      "Training regressor 248/507\n",
      "Training regressor 249/507\n",
      "Training regressor 250/507\n",
      "Training regressor 251/507\n",
      "Training regressor 252/507\n",
      "Training regressor 253/507\n",
      "Training regressor 254/507\n",
      "Training regressor 255/507\n",
      "Training regressor 256/507\n",
      "Training regressor 257/507\n",
      "Training regressor 258/507\n",
      "Training regressor 259/507\n",
      "Training regressor 260/507\n",
      "Training regressor 261/507\n",
      "Training regressor 262/507\n",
      "Training regressor 263/507\n",
      "Training regressor 264/507\n",
      "Training regressor 265/507\n",
      "Training regressor 266/507\n",
      "Training regressor 267/507\n",
      "Training regressor 268/507\n",
      "Training regressor 269/507\n",
      "Training regressor 270/507\n",
      "Training regressor 271/507\n",
      "Training regressor 272/507\n",
      "Training regressor 273/507\n",
      "Training regressor 274/507\n",
      "Training regressor 275/507\n",
      "Training regressor 276/507\n",
      "Training regressor 277/507\n",
      "Training regressor 278/507\n",
      "Training regressor 279/507\n",
      "Training regressor 280/507\n",
      "Training regressor 281/507\n",
      "Training regressor 282/507\n",
      "Training regressor 283/507\n",
      "Training regressor 284/507\n",
      "Training regressor 285/507\n",
      "Training regressor 286/507\n",
      "Training regressor 287/507\n",
      "Training regressor 288/507\n",
      "Training regressor 289/507\n",
      "Training regressor 290/507\n",
      "Training regressor 291/507\n",
      "Training regressor 292/507\n",
      "Training regressor 293/507\n",
      "Training regressor 294/507\n",
      "Training regressor 295/507\n",
      "Training regressor 296/507\n",
      "Training regressor 297/507\n",
      "Training regressor 298/507\n",
      "Training regressor 299/507\n",
      "Training regressor 300/507\n",
      "Training regressor 301/507\n",
      "Training regressor 302/507\n",
      "Training regressor 303/507\n",
      "Training regressor 304/507\n",
      "Training regressor 305/507\n",
      "Training regressor 306/507\n",
      "Training regressor 307/507\n",
      "Training regressor 308/507\n",
      "Training regressor 309/507\n",
      "Training regressor 310/507\n",
      "Training regressor 311/507\n",
      "Training regressor 312/507\n",
      "Training regressor 313/507\n",
      "Training regressor 314/507\n",
      "Training regressor 315/507\n",
      "Training regressor 316/507\n",
      "Training regressor 317/507\n",
      "Training regressor 318/507\n",
      "Training regressor 319/507\n",
      "Training regressor 320/507\n",
      "Training regressor 321/507\n",
      "Training regressor 322/507\n",
      "Training regressor 323/507\n",
      "Training regressor 324/507\n",
      "Training regressor 325/507\n",
      "Training regressor 326/507\n",
      "Training regressor 327/507\n",
      "Training regressor 328/507\n",
      "Training regressor 329/507\n",
      "Training regressor 330/507\n",
      "Training regressor 331/507\n",
      "Training regressor 332/507\n",
      "Training regressor 333/507\n",
      "Training regressor 334/507\n",
      "Training regressor 335/507\n",
      "Training regressor 336/507\n",
      "Training regressor 337/507\n",
      "Training regressor 338/507\n",
      "Training regressor 339/507\n",
      "Training regressor 340/507\n",
      "Training regressor 341/507\n",
      "Training regressor 342/507\n",
      "Training regressor 343/507\n",
      "Training regressor 344/507\n",
      "Training regressor 345/507\n",
      "Training regressor 346/507\n",
      "Training regressor 347/507\n",
      "Training regressor 348/507\n",
      "Training regressor 349/507\n",
      "Training regressor 350/507\n",
      "Training regressor 351/507\n",
      "Training regressor 352/507\n",
      "Training regressor 353/507\n",
      "Training regressor 354/507\n",
      "Training regressor 355/507\n",
      "Training regressor 356/507\n",
      "Training regressor 357/507\n",
      "Training regressor 358/507\n",
      "Training regressor 359/507\n",
      "Training regressor 360/507\n",
      "Training regressor 361/507\n",
      "Training regressor 362/507\n",
      "Training regressor 363/507\n",
      "Training regressor 364/507\n",
      "Training regressor 365/507\n",
      "Training regressor 366/507\n",
      "Training regressor 367/507\n",
      "Training regressor 368/507\n",
      "Training regressor 369/507\n",
      "Training regressor 370/507\n",
      "Training regressor 371/507\n",
      "Training regressor 372/507\n",
      "Training regressor 373/507\n",
      "Training regressor 374/507\n",
      "Training regressor 375/507\n",
      "Training regressor 376/507\n",
      "Training regressor 377/507\n",
      "Training regressor 378/507\n",
      "Training regressor 379/507\n",
      "Training regressor 380/507\n",
      "Training regressor 381/507\n",
      "Training regressor 382/507\n",
      "Training regressor 383/507\n",
      "Training regressor 384/507\n",
      "Training regressor 385/507\n",
      "Training regressor 386/507\n",
      "Training regressor 387/507\n",
      "Training regressor 388/507\n",
      "Training regressor 389/507\n",
      "Training regressor 390/507\n",
      "Training regressor 391/507\n",
      "Training regressor 392/507\n",
      "Training regressor 393/507\n",
      "Training regressor 394/507\n",
      "Training regressor 395/507\n",
      "Training regressor 396/507\n",
      "Training regressor 397/507\n",
      "Training regressor 398/507\n",
      "Training regressor 399/507\n",
      "Training regressor 400/507\n",
      "Training regressor 401/507\n",
      "Training regressor 402/507\n",
      "Training regressor 403/507\n",
      "Training regressor 404/507\n",
      "Training regressor 405/507\n",
      "Training regressor 406/507\n",
      "Training regressor 407/507\n",
      "Training regressor 408/507\n",
      "Training regressor 409/507\n",
      "Training regressor 410/507\n",
      "Training regressor 411/507\n",
      "Training regressor 412/507\n",
      "Training regressor 413/507\n",
      "Training regressor 414/507\n",
      "Training regressor 415/507\n",
      "Training regressor 416/507\n",
      "Training regressor 417/507\n",
      "Training regressor 418/507\n",
      "Training regressor 419/507\n",
      "Training regressor 420/507\n",
      "Training regressor 421/507\n",
      "Training regressor 422/507\n",
      "Training regressor 423/507\n",
      "Training regressor 424/507\n",
      "Training regressor 425/507\n",
      "Training regressor 426/507\n",
      "Training regressor 427/507\n",
      "Training regressor 428/507\n",
      "Training regressor 429/507\n",
      "Training regressor 430/507\n",
      "Training regressor 431/507\n",
      "Training regressor 432/507\n",
      "Training regressor 433/507\n",
      "Training regressor 434/507\n",
      "Training regressor 435/507\n",
      "Training regressor 436/507\n",
      "Training regressor 437/507\n",
      "Training regressor 438/507\n",
      "Training regressor 439/507\n",
      "Training regressor 440/507\n",
      "Training regressor 441/507\n",
      "Training regressor 442/507\n",
      "Training regressor 443/507\n",
      "Training regressor 444/507\n",
      "Training regressor 445/507\n",
      "Training regressor 446/507\n",
      "Training regressor 447/507\n",
      "Training regressor 448/507\n",
      "Training regressor 449/507\n",
      "Training regressor 450/507\n",
      "Training regressor 451/507\n",
      "Training regressor 452/507\n",
      "Training regressor 453/507\n",
      "Training regressor 454/507\n",
      "Training regressor 455/507\n",
      "Training regressor 456/507\n",
      "Training regressor 457/507\n",
      "Training regressor 458/507\n",
      "Training regressor 459/507\n",
      "Training regressor 460/507\n",
      "Training regressor 461/507\n",
      "Training regressor 462/507\n",
      "Training regressor 463/507\n",
      "Training regressor 464/507\n",
      "Training regressor 465/507\n",
      "Training regressor 466/507\n",
      "Training regressor 467/507\n",
      "Training regressor 468/507\n",
      "Training regressor 469/507\n",
      "Training regressor 470/507\n",
      "Training regressor 471/507\n",
      "Training regressor 472/507\n",
      "Training regressor 473/507\n",
      "Training regressor 474/507\n",
      "Training regressor 475/507\n",
      "Training regressor 476/507\n",
      "Training regressor 477/507\n",
      "Training regressor 478/507\n",
      "Training regressor 479/507\n",
      "Training regressor 480/507\n",
      "Training regressor 481/507\n",
      "Training regressor 482/507\n",
      "Training regressor 483/507\n",
      "Training regressor 484/507\n",
      "Training regressor 485/507\n",
      "Training regressor 486/507\n",
      "Training regressor 487/507\n",
      "Training regressor 488/507\n",
      "Training regressor 489/507\n",
      "Training regressor 490/507\n",
      "Training regressor 491/507\n",
      "Training regressor 492/507\n",
      "Training regressor 493/507\n",
      "Training regressor 494/507\n",
      "Training regressor 495/507\n",
      "Training regressor 496/507\n",
      "Training regressor 497/507\n",
      "Training regressor 498/507\n",
      "Training regressor 499/507\n",
      "Training regressor 500/507\n",
      "Training regressor 501/507\n",
      "Training regressor 502/507\n",
      "Training regressor 503/507\n",
      "Training regressor 504/507\n",
      "Training regressor 505/507\n",
      "Training regressor 506/507\n",
      "Training regressor 507/507\n",
      "Training generic regressor\n"
     ]
    }
   ],
   "source": [
    "model_idx = len(pipes) - 1\n",
    "model_name = pipes[model_idx][\"name\"]\n",
    "pipe = pipes[model_idx][\"model\"]\n",
    "\n",
    "display(model_name)\n",
    "display(pipe)\n",
    "\n",
    "df_ = df.copy()\n",
    "pipe = pipe.fit(df_.drop(columns=[Y_COLUMN]), df_[Y_COLUMN])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:38:21.475272Z",
     "start_time": "2023-06-28T17:36:31.737697Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(507, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([ 1.10693245e+00, -2.56348071e-01,  2.01871174e-18,  5.15613496e-03,\n        2.86548983e-04])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe[\"regressor\"].coef_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:38:28.300597Z",
     "start_time": "2023-06-28T17:38:28.278200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "y_val_pred = np.clip(\n",
    "    pipe.predict(X_val),\n",
    "    0, 1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:38:39.066596Z",
     "start_time": "2023-06-28T17:38:34.540712Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "\"fname='./results/v3_5.csv'\""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(index=X_val.index, data=y_val_pred.values, columns=[Y_COLUMN]).reset_index()\n",
    "fname = f'./results/v3_{model_idx}.csv'\n",
    "display(f'{fname=}')\n",
    "predictions.to_csv(fname, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:41:04.838570Z",
     "start_time": "2023-06-28T17:41:04.250685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "(54999,)"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred.values.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:40:58.174271Z",
     "start_time": "2023-06-28T17:40:58.150879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "X_val_ = X_val.assign(y_pred=y_val_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:41:09.920348Z",
     "start_time": "2023-06-28T17:41:09.871147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='y_pred', ylabel='Count'>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=X_val_, x='y_pred')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:38:46.870840Z",
     "start_time": "2023-06-28T17:38:45.532685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "'> kaggle competitions submit -c bike-availability-prediction -f ./results/v3_5.csv -m \"V3: 1 regression per station (more features)\"'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.30M/1.30M [01:53<00:00, 12.0kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Bike Availability Prediction"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "statement = f'kaggle competitions submit -c bike-availability-prediction -f {fname} -m \"V3: {model_name}\"'\n",
    "display('> ' + statement)\n",
    "os.system(f'kaggle competitions submit -c bike-availability-prediction -f {fname} -m \"V3: {model_name}\"')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:43:34.030679Z",
     "start_time": "2023-06-28T17:41:14.967890Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T17:19:06.137991Z",
     "start_time": "2023-06-28T17:19:06.132466Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
