{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-27T12:57:04.160662Z",
     "start_time": "2023-06-27T12:57:04.144315Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\n\u001B[1;32m      3\u001B[0m M, m, p \u001B[38;5;241m=\u001B[39m sklearn\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m M \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m m \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "M, m, p = sklearn.__version__.split('.')\n",
    "display(sklearn.__version__)\n",
    "assert int(M) == 1\n",
    "assert int(m) >= 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T12:56:43.567753Z",
     "start_time": "2023-06-27T12:56:41.882413Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_folders = [\n",
    "    pathlib.Path(f'./data/bicing/truncated/{y}') for y in [2022]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pandas_kwargs = {\n",
    "    'index_col': 0,\n",
    "}\n",
    "df = pd.concat([pd.read_csv(file, **pandas_kwargs) for data_folder in data_folders for file in\n",
    "                data_folder.glob('*/*.csv')]).drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    datetime=lambda x: pd.to_datetime(x.datetime),\n",
    "    percentage_docks_available=df.num_docks_available / (df.num_docks_available + df.num_bikes_available),\n",
    ").drop(columns=['num_docks_available', 'num_bikes_available']).sort_values(['station_id', 'datetime'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add station info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "station_info = pd.read_csv('./data/bicing_info.csv')\n",
    "df = pd.merge(left=df, right=station_info[['station_id', 'lat', 'lon', 'altitude', 'post_code']],\n",
    "              on=['station_id'])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### climate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_climate_ = pd.read_csv('./data/clima.csv', parse_dates=['time'])\n",
    "\n",
    "df_climate = df_climate_.assign(\n",
    "    year=df_climate_.time.dt.year,\n",
    "    month=df_climate_.time.dt.month,\n",
    "    day=df_climate_.time.dt.day,\n",
    "    hour=df_climate_.time.dt.hour\n",
    ")\n",
    "df = pd.merge(left=df, right=df_climate.drop(columns=['time']), on=['hour', 'day', 'month', 'year'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# merge with previous hours\n",
    "df = df.sort_values(['station_id', 'datetime']).assign(\n",
    "    day_of_week=lambda x: x.datetime.dt.day_of_week,\n",
    "    is_weekend=lambda x: x.day_of_week >= 5,\n",
    "    is_night=lambda x: np.bitwise_or(x.hour >= 20, x.hour <= 7),\n",
    "    is_work_morning=lambda x: np.bitwise_and(x.hour >= 6, x.hour <= 10) & np.bitwise_not(x.is_weekend),\n",
    "    is_summer=lambda x: x.month.between(6, 8),\n",
    "    ctx_1=lambda x: x.percentage_docks_available.shift(1),\n",
    "    ctx_2=lambda x: x.percentage_docks_available.shift(2),\n",
    "    ctx_3=lambda x: x.percentage_docks_available.shift(3),\n",
    "    ctx_4=lambda x: x.percentage_docks_available.shift(4),\n",
    "    station_id_aux=lambda x: x.station_id.shift(4),\n",
    "    altitude=lambda x: x.altitude.astype(int)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.query('not ctx_1.isnull()') \\\n",
    "    .query('not ctx_2.isnull()') \\\n",
    "    .query('not ctx_3.isnull()') \\\n",
    "    .query('not ctx_4.isnull()') \\\n",
    "    .query('station_id == station_id_aux') \\\n",
    "    .drop(columns=['station_id_aux']) \\\n",
    "    .query('not percentage_docks_available.isnull()')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfnans = df.isna().sum()\n",
    "assert dfnans[dfnans > 0].empty"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import model_selection, linear_model, ensemble, neighbors, preprocessing, metrics, pipeline, compose"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CrossValidation\n",
    "\n",
    "scoring = 'neg_root_mean_squared_error'\n",
    "\n",
    "\n",
    "def get_cv_scores(model, X: pd.DataFrame, y: pd.Series, cv=4, verbose=0):\n",
    "    if verbose > 0: display(f'{X.shape=}')\n",
    "    if verbose > 0: display(f'{y.shape=}')\n",
    "\n",
    "    return model_selection.cross_val_score(\n",
    "        model, X, y,\n",
    "        scoring=scoring,\n",
    "        cv=model_selection.TimeSeriesSplit(cv),\n",
    "        verbose=verbose,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    data=df[[\n",
    "        'lat',\n",
    "        'lon',\n",
    "        'altitude',\n",
    "        'temperature_2m',\n",
    "        'total_cloud_cover',\n",
    "        'total_precipitation',\n",
    "        'windspeed_10m',\n",
    "        'day_of_week',\n",
    "        'ctx_1',\n",
    "        'ctx_2',\n",
    "        'ctx_3',\n",
    "        'ctx_4',\n",
    "        'percentage_docks_available',\n",
    "    ]].sample(frac=0.0001)\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.savefig('./fig.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom Regressor\n",
    "from dataclasses import dataclass\n",
    "from sklearn import linear_model\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# create model per\n",
    "@dataclass\n",
    "class BicingRegression:\n",
    "    grouping_column_name: str\n",
    "\n",
    "    regressor_class: type = None\n",
    "    verbose: int = 0\n",
    "\n",
    "    groups_: List[int] = None\n",
    "    regressors_: Dict[int, object] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.regressors_ = self.regressors_ or {}\n",
    "        self.regressor_class = self.regressor_class or linear_model.LinearRegression\n",
    "\n",
    "    def fit(self, X, y, weights=None):\n",
    "        if self.verbose >= 10:\n",
    "            print(f'{type(X)=}')\n",
    "            print(f'{type(y)=}')\n",
    "        self.groups_ = X.loc[:, self.grouping_column_name].unique()\n",
    "\n",
    "        for ii, group in enumerate(self.groups_):\n",
    "            if self.verbose > 0:\n",
    "                print(f'Training regressor {ii + 1}/{len(self.groups_)}')\n",
    "            self.regressors_[group] = self.regressor_class()\n",
    "\n",
    "            X_ = X.query(f'{self.grouping_column_name} == {group}')\n",
    "            y_ = y.loc[X_.index]\n",
    "\n",
    "            self.regressors_[group].fit(X_, y_)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = pd.DataFrame(\n",
    "            index=X.index,\n",
    "            columns=['prediction']\n",
    "        )\n",
    "\n",
    "        for group in self.groups_:\n",
    "            X_ = X.query(f'{self.grouping_column_name} == {group}')\n",
    "            if len(X_) == 0:\n",
    "                continue\n",
    "            y_pred = self.regressors_[group].predict(X_)\n",
    "            results.loc[X_.index, 'prediction'] = y_pred\n",
    "\n",
    "        return results['prediction']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipes = [\n",
    "    {\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "                    ],\n",
    "                    remainder=\"drop\")\n",
    "                 ),\n",
    "                (\"regressor\", linear_model.LinearRegression())\n",
    "            ]\n",
    "        ),\n",
    "        'weights': None,\n",
    "    },\n",
    "    {\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "                        ('std', preprocessing.StandardScaler(), [\"altitude\"]),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", linear_model.LinearRegression())\n",
    "            ]\n",
    "        ),\n",
    "        'weights': None,\n",
    "    },\n",
    "    {\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "                        ('std', preprocessing.StandardScaler(), [\"temperature_2m\"]),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", linear_model.LinearRegression())\n",
    "            ]\n",
    "        ),\n",
    "        'weights': None,\n",
    "    },\n",
    "    {\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "                        ('std', preprocessing.StandardScaler(), [\"temperature_2m\", \"altitude\"]),\n",
    "                    ],\n",
    "                    remainder=\"drop\", )\n",
    "                 ),\n",
    "                (\"regressor\", linear_model.LinearRegression())\n",
    "            ]\n",
    "        ),\n",
    "        'weights': None,\n",
    "    },\n",
    "    {\n",
    "        'model': pipeline.Pipeline(\n",
    "            [\n",
    "                (\"transformer\", compose.ColumnTransformer(\n",
    "                    [\n",
    "                        ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "                        ('std', preprocessing.StandardScaler(), [\"temperature_2m\", \"altitude\"]),\n",
    "                        ('coord', preprocessing.StandardScaler(), [\"lat\", \"lon\"]),\n",
    "                        ('cat', preprocessing.OneHotEncoder(handle_unknown=\"ignore\"), [\"post_code\"]),\n",
    "                        ('clean', preprocessing.FunctionTransformer(feature_names_out='one-to-one'), ['station_id']),\n",
    "                    ],\n",
    "                    remainder=\"drop\",\n",
    "                    sparse_threshold=0,\n",
    "                )\n",
    "                 ),\n",
    "                (\"regressor\", BicingRegression(\n",
    "                    grouping_column_name='clean__station_id',\n",
    "                    verbose=10\n",
    "                ))\n",
    "            ]\n",
    "        ),\n",
    "        'weights': None,\n",
    "    },\n",
    "    # {\n",
    "    #     'model': pipeline.Pipeline(\n",
    "    #         [\n",
    "    #             (\"transformer\", compose.ColumnTransformer(\n",
    "    #                 [\n",
    "    #                     ('bool', preprocessing.OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "    #                      [\"is_weekend\", \"is_summer\", \"is_night\"]),\n",
    "    #                     ('previous_hours', preprocessing.MinMaxScaler((0, 1)), [f\"ctx_{ii + 1}\" for ii in range(4)]),\n",
    "    #                     ('4bins', preprocessing.KBinsDiscretizer(n_bins=4, encode='onehot', strategy='uniform'),\n",
    "    #                      [\"hour\", \"month\"]),\n",
    "    #                     ('2bins', preprocessing.KBinsDiscretizer(n_bins=2, encode='onehot', strategy='uniform'),\n",
    "    #                      [\"temperature_2m\"]),\n",
    "    #                 ],\n",
    "    #                 remainder=\"drop\", )\n",
    "    #              ),\n",
    "    #             (\"regressor\", linear_model.LinearRegression())\n",
    "    #         ]\n",
    "    #     ),\n",
    "    #     'weights': None,\n",
    "    # },\n",
    "]\n",
    "\n",
    "Y_COLUMN = 'percentage_docks_available'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ = df.sort_values('datetime')\n",
    "SHOW_CV_STEPS = True\n",
    "cv = model_selection.TimeSeriesSplit(2)\n",
    "\n",
    "for ii, dd in enumerate(pipes[-1:]):\n",
    "    pipe = dd['model']\n",
    "    display(f'Running model with IDX: {ii}')\n",
    "    display(pipe)\n",
    "\n",
    "    # this is a sklearn 1.2.0 feature:\n",
    "    pipe[\"transformer\"].set_output('pandas')\n",
    "\n",
    "    if SHOW_CV_STEPS:\n",
    "        for ii, (train_idx, test_idx) in enumerate(cv.split(df_.drop(columns=[Y_COLUMN]))):\n",
    "            df_train_ = df_.iloc[train_idx]\n",
    "            df_test_ = df_.iloc[test_idx]\n",
    "\n",
    "            pipe.fit(df_train_.drop(columns=[Y_COLUMN]), df_train_[Y_COLUMN])\n",
    "            display(\n",
    "                pd.Series(\n",
    "                    data=pipe[\"regressor\"].coef_,\n",
    "                    index=pipe[\"transformer\"].get_feature_names_out()\n",
    "                )\n",
    "            )\n",
    "            y_test_pred = pipe.predict(df_test_.drop(columns=[Y_COLUMN]))\n",
    "            sns.scatterplot(\n",
    "                x=df_test_[Y_COLUMN],\n",
    "                y=y_test_pred,\n",
    "                alpha=0.2\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "    cv_scores = get_cv_scores(pipe, df_.drop(columns=[Y_COLUMN]), df_[Y_COLUMN], cv=3, verbose=0)\n",
    "    display(f'{np.mean(cv_scores):0.4f}')\n",
    "\n",
    "    display('-' * 80)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# final fit"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe.fit(df.drop(columns=[Y_COLUMN]), df[Y_COLUMN])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load X_val\n",
    "X_val = pd.read_csv('./data/validation/X_validation.csv', index_col=\"index\")\n",
    "X_val = pd.merge(left=X_val, right=station_info[['station_id', 'lat', 'lon', 'altitude', 'post_code']],\n",
    "                 on=['station_id'])\n",
    "X_val = pd.merge(left=X_val, right=df_climate.drop(columns=['time']), on=['hour', 'day', 'month', 'year'])\n",
    "\n",
    "X_val = X_val.assign(\n",
    "    year=2023,\n",
    "    date=lambda x: pd.to_datetime(dict(year=x.year, month=x.month, day=x.day)),\n",
    "    day_of_week=lambda x: x.date.dt.day_of_week,\n",
    "    is_weekend=lambda x: x.day_of_week >= 5,\n",
    "    is_night=lambda x: np.bitwise_or(x.hour >= 20, x.hour <= 7),\n",
    "    is_work_morning=lambda x: np.bitwise_and(x.hour >= 6, x.hour <= 10) & np.bitwise_not(x.is_weekend),\n",
    "    is_summer=lambda x: x.month.between(6, 8),\n",
    ").rename(\n",
    "    columns={\n",
    "        'ctx-1': 'ctx_1',\n",
    "        'ctx-2': 'ctx_2',\n",
    "        'ctx-3': 'ctx_3',\n",
    "        'ctx-4': 'ctx_4',\n",
    "    }\n",
    ")\n",
    "\n",
    "X_val.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 3.32007294e-01, -1.32621617e-01,  3.93000430e-02,  8.28586837e-03,\n       -1.42041137e+01, -8.62731006e-03, -1.27760547e+00,  0.00000000e+00,\n       -2.55521093e+00,  0.00000000e+00])"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 7\n",
    "y_val = pd.DataFrame(\n",
    "    pipe.predict(X_val),\n",
    "    index=X_val.index,\n",
    "    columns=[Y_COLUMN]\n",
    ").assign(index=X_val.index)[['index', \"percentage_docks_available\"]]\n",
    "\n",
    "display(y_val.head())\n",
    "\n",
    "y_val.to_csv(f'./results/v2_{n}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T10:22:50.006847Z",
     "start_time": "2023-06-27T10:22:49.994815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
